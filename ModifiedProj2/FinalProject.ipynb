{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function/Class Definitions & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:43:56.968674Z",
     "start_time": "2025-05-02T15:43:56.965838Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/raw' # Where all the raw stories are\n",
    "TRAIN_FILE = 'data/dataset.jsonl'\n",
    "TEST_FILE = 'data/dataset.jsonl'\n",
    "CORPUS_FILE = 'corpus.txt' # Where all the raw data will be stored\n",
    "MODEL_WEIGHTS_DIR = \"final_model_weights.pth\"\n",
    "\n",
    "TOKENIZER_PREFIX = 'bpe_model' # Tokenizer name\n",
    "TOKENIZER_PATH = TOKENIZER_PREFIX + \".model\"\n",
    "PAD_TOKEN_ID = 5\n",
    "\n",
    "VOCAB_SIZE = 7017\n",
    "MAX_TRAIN_SEQ_LEN = 1024\n",
    "MAX_GEN_SEQ_LEN = 1024\n",
    "\n",
    "\n",
    "#MODIFIABLE CONSTANTS FOR MODEL TRAINING START HERE\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = .002\n",
    "# Dictates creativity of the model, < 1 more deterministic, > 1 more creative/stochastic, 1 is no change from base model.\n",
    "TEMPERATURE = .9\n",
    "EARLY_EPOCH_STOP = 2\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT = .2\n",
    "N_HEADS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:43:57.682953Z",
     "start_time": "2025-05-02T15:43:56.971060Z"
    }
   },
   "outputs": [],
   "source": [
    "from FinalProjHelper import *\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    This function takes in all of the batches from the dataset, which will be jagged arrays, and\n",
    "    inserts padding tokens <pad> such that all of the sequences are the same length. Note that the\n",
    "    Cross Entropy Loss criterion should specify to ignore the index 3 so it does not affect the training.\n",
    "\n",
    "    :param batch: The batch of prompts and completions that form a jagged array to be padded.\n",
    "    :return: The input and label batches properly padded.\n",
    "    \"\"\"\n",
    "\n",
    "    enc_input_batch, dec_input_batch, target_batch = zip(*batch)\n",
    "    enc_input_batch = nn.utils.rnn.pad_sequence(enc_input_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    dec_input_batch = nn.utils.rnn.pad_sequence(dec_input_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    target_batch = nn.utils.rnn.pad_sequence(target_batch, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    return enc_input_batch, dec_input_batch, target_batch\n",
    "\n",
    "def train_model(model, device, tokenizer, model_type=\"\"):\n",
    "    \"\"\"\n",
    "    The main training code generalized for all of the models,\n",
    "    including evaluation metrics such as loss graphs, BLEU score, and Perplexity score.\n",
    "\n",
    "    :param model: The instantiated model needing training.\n",
    "    :param device: The device the model should be trained on, preferrably cuda.\n",
    "    :param tokenizer: The loaded tokenizer trained on the dataset being used for model training.\n",
    "    :return: The progression of training and testing losses.\n",
    "    \"\"\"\n",
    "    # Loading tokenizer file and getting most up to date vocab size\n",
    "    vocab_size = tokenizer.get_piece_size()\n",
    "    print('v size: ', vocab_size)\n",
    "\n",
    "    # Set up datasets from the given jsonl files for training\n",
    "    train_data = TextDatasetTED(TRAIN_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n",
    "    test_data = TextDatasetTED(TEST_FILE, tokenizer, MAX_TRAIN_SEQ_LEN)\n",
    "\n",
    "    # Using pytorch DataLoaders for easy batching, shuffling, etc.\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Adding on a decaying learning rate to the optimizer\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        #Emptying cache and unused data on every epoch since CUDA would run out of memory otherwise\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "        #Want the model in training mode\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for enc_input_ids, dec_input_ids, target_ids in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            enc_input_ids = enc_input_ids.to(device)\n",
    "            dec_input_ids = dec_input_ids.to(device)\n",
    "            target_ids = target_ids.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get the padding masks for proper training\n",
    "            enc_pad_mask = (enc_input_ids == PAD_TOKEN_ID)\n",
    "            dec_pad_mask = (dec_input_ids == PAD_TOKEN_ID)\n",
    "\n",
    "            # Getting the probability distributions for the prompts...\n",
    "            logits = model(enc_input_ids, dec_input_ids, enc_pad_mask, dec_pad_mask)\n",
    "\n",
    "            \"\"\"\n",
    "            For understanding this dimension change, understand that the logits are of\n",
    "            dimension (B,S,V) (see forward() function of base model for explanantion) and the targets are of\n",
    "            dimension (B,S) (where each entry is the correct token to predict for that position in the sequence).\n",
    "\n",
    "            For Cross Entropy Loss, we must have 1 prediction for each row in both tensors. Therefore, if we can reduce\n",
    "            each tensor such that it reads the last dimension for each row, the function will work. Aka we would have\n",
    "            dimension (B x S, V) (every row is a token's probability distribution) and\n",
    "            dimension (B x S) (every entry is that token's correct value, in chronological order with the logits)\n",
    "\n",
    "            The .view() function allows us to do this my making the last dimension of each tensor account for each entry.\n",
    "            \"\"\"\n",
    "            loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "\n",
    "            # Adjusting weights...\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Don't want the model to train on testing data, so .eval()\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "\n",
    "        # Evaluate testing loss after training on this epoch to see performance on new data\n",
    "        with torch.no_grad():\n",
    "            for enc_input_ids, dec_input_ids, target_ids in test_loader:\n",
    "                enc_input_ids = enc_input_ids.to(device)\n",
    "                dec_input_ids = dec_input_ids.to(device)\n",
    "                target_ids = target_ids.to(device)\n",
    "\n",
    "                # Get the padding masks for proper training\n",
    "                enc_pad_mask = (enc_input_ids == PAD_TOKEN_ID)\n",
    "                dec_pad_mask = (dec_input_ids == PAD_TOKEN_ID)\n",
    "\n",
    "                # Getting the probability distributions for the prompts...\n",
    "                logits = model(enc_input_ids, dec_input_ids, enc_pad_mask, dec_pad_mask)\n",
    "\n",
    "                loss = criterion(logits.view(-1, vocab_size), target_ids.view(-1))\n",
    "                total_test_loss += loss.item()\n",
    "\n",
    "            avg_test_loss = total_test_loss / len(test_loader)\n",
    "            test_losses.append(avg_test_loss)\n",
    "            scheduler.step(avg_test_loss)\n",
    "\n",
    "            # If our testing data starts getting worse over time, we can stop it early to reduce losses in accuracy based on a preset constant\n",
    "            if(avg_test_loss < best_test_loss):\n",
    "                best_test_loss = avg_test_loss\n",
    "                no_improve_epochs = 0\n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "\n",
    "        if(no_improve_epochs >= EARLY_EPOCH_STOP):\n",
    "            print(f\"No improvement in {EARLY_EPOCH_STOP} epochs, stopping...\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), MODEL_WEIGHTS_DIR)\n",
    "    print(f\"Saved model weights to {MODEL_WEIGHTS_DIR}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Test Loss={avg_test_loss:.4f}\")\n",
    "    print(f\"Model Perplexity: {Perplexity(avg_train_loss):.4f} Model BLEU: {BLEU(model, tokenizer, test_loader):.4f}\")\n",
    "    plotLossOverEpochs(len(train_losses), train_losses, test_losses, model_type)\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "def plotLossOverEpochs(epochs, train_loss, test_loss, model_type=\"\"):\n",
    "        \"\"\"\n",
    "        Creates a plot showing the losses over time for a model.\n",
    "\n",
    "        :param epochs: The number of epochs the training took place over\n",
    "        :param train_loss: The losses of training over the epochs\n",
    "        :param test_loss: The losses of testing over the epochs\n",
    "        :param name: The name of the trained model being evaluated\n",
    "        \"\"\"\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(model_type + \" Loss per Epoch\")\n",
    "\n",
    "        x_range = range(1, epochs + 1)\n",
    "\n",
    "        plt.plot(x_range, train_loss)\n",
    "        plt.plot(x_range, test_loss)\n",
    "\n",
    "        plt.plot(x_range, train_loss, label=\"Training Loss\", color='blue')\n",
    "        plt.plot(x_range, test_loss, label=\"Testing Loss\", color='orange')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "#Because the loss is already cross entropy, we can just do the natural exponentiation of the loss\n",
    "#Loss here is the average loss across tokens\n",
    "def Perplexity(loss):\n",
    "    return math.exp(loss)\n",
    "\n",
    "def BLEU(model, tokenizer, test_loader):\n",
    "    \"\"\"\n",
    "        Evaluates BLEU score of the entire model by getting probabilities.\n",
    "\n",
    "        :param epochs: The number of epochs the training took place over\n",
    "        :param train_loss: The losses of training over the epochs\n",
    "        :param test_loss: The losses of testing over the epochs\n",
    "        :param name: The name of the trained model being evaluated\n",
    "        :return: The overall BLEU scoring of the prompts and completions ran on\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    references = []\n",
    "    candidates = []\n",
    "    samples_processed = 0\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # We really just want the raw prompts and completions to get rid of unnecessary padding\n",
    "        for enc_input_ids, dec_input_ids, target_ids in test_loader:\n",
    "\n",
    "            enc_input_ids = enc_input_ids.to(DEVICE)\n",
    "            dec_input_ids = dec_input_ids.to(DEVICE)\n",
    "            target_ids = target_ids.to(DEVICE)\n",
    "\n",
    "            # Get the padding masks for proper training\n",
    "            enc_pad_mask = (enc_input_ids == PAD_TOKEN_ID)\n",
    "            dec_pad_mask = (dec_input_ids == PAD_TOKEN_ID)\n",
    "\n",
    "            # The model does teacher forcing predictions, which is exactly what we need to compare with the labels\n",
    "            logits = model(enc_input_ids, dec_input_ids, enc_pad_mask, dec_pad_mask)\n",
    "\n",
    "            # Taking the best token from each probability distribution for comparison against the labels\n",
    "            predicted_ids = torch.argmax(logits, dim=-1).cpu().tolist()\n",
    "            target_ids = target_ids.cpu().tolist()\n",
    "\n",
    "            for predicted, target in zip(predicted_ids, target_ids):\n",
    "\n",
    "                # Process 250 samples so it doesnt run forever\n",
    "                if samples_processed > 250:\n",
    "                    break\n",
    "\n",
    "                # For each prediction vector and label vector, decode it and add it to a list for BLEU scoring\n",
    "                pred_decode = tokenizer.decode(predicted, out_type=str)\n",
    "                reference = tokenizer.decode(target, out_type=str)\n",
    "\n",
    "                samples_processed += 1\n",
    "\n",
    "                candidates.append(pred_decode.split())\n",
    "                references.append([reference.split()])\n",
    "\n",
    "    # Compute the corpus-level BLEU score. For the purposes of this project, up to 3-gram comparisons were made\n",
    "    bleu_score = corpus_bleu(references, candidates, weights=(.25, .25, .25, .25), smoothing_function=smoothing_function)\n",
    "    return bleu_score\n",
    "\n",
    "def prompt_model(model, tokenizer, name):\n",
    "    while(1):\n",
    "        print(\"Prompt \" + name + \" (type q to quit): \")\n",
    "        prompt = input()\n",
    "        if prompt.lower() == \"q\":\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Your unit test: \" + model.generate(tokenizer,\n",
    "                                                       prompt,\n",
    "                                                       max_seq_length=MAX_GEN_SEQ_LEN,\n",
    "                                                       bos_token_id=BOS_TOKEN_ID,\n",
    "                                                       eos_token_id=EOS_TOKEN_ID,\n",
    "                                                       pad_token_id=PAD_TOKEN_ID,\n",
    "                                                       temperature=TEMPERATURE,\n",
    "                                                       device=DEVICE\n",
    "                                                      ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer & Preliminary Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:44:01.383669Z",
     "start_time": "2025-05-02T15:43:57.712839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected V size:  7017\n",
      "def my_func ( lalala : str ) -> List [ int ] : \n",
      "     print ( \"foo bar\" ) \n",
      "     return [ 3 , 1 , 4 , 1 , 5 , 9 ] \n",
      " \n",
      "piece size:  7017  and vocab size:  7017\n",
      "<unk>\n",
      "<s>\n",
      "</s>\n",
      "<BOS>\n",
      "<EOS>\n",
      "<PAD>\n",
      "\\n\n",
      "<INDENT>\n",
      "<DEDENT>\n",
      "▁(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/token_input.txt\n",
      "  input_format: \n",
      "  model_prefix: bpe_model\n",
      "  model_type: BPE\n",
      "  vocab_size: 7017\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 8\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <BOS>\n",
      "  user_defined_symbols: <EOS>\n",
      "  user_defined_symbols: <PAD>\n",
      "  user_defined_symbols: \\n\n",
      "  user_defined_symbols: <INDENT>\n",
      "  user_defined_symbols: <DEDENT>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: data/token_input.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (19507 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 20642 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 489 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <BOS>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: \\n\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <INDENT>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <DEDENT>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=3771245\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=328\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 19174 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 19174\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 29451\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51029 min_freq=81\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23462 size=20 all=4016 active=1582 piece=▁...\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9873 size=40 all=5017 active=2583 piece=▁in\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7462 size=60 all=5752 active=3318 piece=ct\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5746 size=80 all=6511 active=4077 piece=ver\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4248 size=100 all=7410 active=4976 piece=mp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4246 min_freq=289\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3585 size=120 all=7907 active=1446 piece=ad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3065 size=140 all=8426 active=1965 piece=▁lo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2634 size=160 all=8964 active=2503 piece=ity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2219 size=180 all=9502 active=3041 piece=CheckDefinition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2021 size=200 all=10002 active=3541 piece=Severity\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2003 min_freq=272\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1753 size=220 all=10385 active=1381 piece=rue\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1596 size=240 all=10735 active=1731 piece=▁P\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1468 size=260 all=11271 active=2267 piece=▁assertEqual\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1322 size=280 all=11718 active=2714 piece=▁file\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1193 size=300 all=12088 active=3084 piece=rror\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1188 min_freq=240\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1092 size=320 all=12543 active=1449 piece=way\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1031 size=340 all=12851 active=1757 piece=dex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=964 size=360 all=13219 active=2125 piece=ord\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=895 size=380 all=13442 active=2348 piece=▁wh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=830 size=400 all=13751 active=2657 piece=cur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=829 min_freq=211\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=774 size=420 all=14081 active=1308 piece=▁text\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=728 size=440 all=14326 active=1553 piece=ding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=695 size=460 all=14646 active=1873 piece=value\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=660 size=480 all=14939 active=2166 piece=▁expected\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=627 size=500 all=15168 active=2395 piece=▁qu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=622 min_freq=189\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=602 size=520 all=15376 active=1202 piece=▁up\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=578 size=540 all=15547 active=1373 piece=ark\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=549 size=560 all=15801 active=1627 piece=lat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=524 size=580 all=16098 active=1924 piece=line\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=502 size=600 all=16311 active=2137 piece=▁update\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=501 min_freq=169\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=481 size=620 all=16539 active=1223 piece=uple\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=461 size=640 all=16761 active=1445 piece=ON\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=450 size=660 all=17003 active=1687 piece=boveSeverity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=437 size=680 all=17219 active=1903 piece=▁values\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=422 size=700 all=17465 active=2149 piece=mpty\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=419 min_freq=152\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=404 size=720 all=17631 active=1160 piece=▁model\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=390 size=740 all=17840 active=1369 piece=Lines\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=381 size=760 all=18052 active=1581 piece=fix\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=370 size=780 all=18168 active=1697 piece=ayment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=800 all=18334 active=1863 piece=Con\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=357 min_freq=139\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=345 size=820 all=18588 active=1206 piece=ll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=331 size=840 all=18764 active=1382 piece=Name\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=324 size=860 all=18940 active=1558 piece=Le\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=880 all=19037 active=1655 piece=MS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=309 size=900 all=19253 active=1871 piece=▁directory\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=308 min_freq=129\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=920 all=19403 active=1151 piece=struct\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=292 size=940 all=19516 active=1264 piece=lines\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=281 size=960 all=19669 active=1417 piece=iti\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=274 size=980 all=19884 active=1632 piece=▁ed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=1000 all=20044 active=1792 piece=▁conver\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=267 min_freq=119\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=1020 all=20171 active=1125 piece=ffi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=255 size=1040 all=20329 active=1283 piece=ang\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=250 size=1060 all=20531 active=1485 piece=ganism\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=243 size=1080 all=20655 active=1609 piece=▁vi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=234 size=1100 all=20798 active=1752 piece=requi\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=234 min_freq=107\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=228 size=1120 all=20974 active=1212 piece=quen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=222 size=1140 all=21059 active=1297 piece=▁must\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=217 size=1160 all=21197 active=1435 piece=▁!=\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=1180 all=21294 active=1532 piece=authenticate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=205 size=1200 all=21439 active=1677 piece=▁keys\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=205 min_freq=99\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=200 size=1220 all=21532 active=1165 piece=IP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=196 size=1240 all=21657 active=1290 piece=ribu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=191 size=1260 all=21762 active=1395 piece=rase\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=185 size=1280 all=21884 active=1517 piece=ion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=182 size=1300 all=22013 active=1646 piece=phrase\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=182 min_freq=90\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=178 size=1320 all=22105 active=1188 piece=equal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=174 size=1340 all=22195 active=1278 piece=no\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=1360 all=22350 active=1433 piece=cache\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=166 size=1380 all=22474 active=1557 piece=cri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=162 size=1400 all=22550 active=1633 piece=licy\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=162 min_freq=84\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=160 size=1420 all=22619 active=1194 piece=▁document\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=156 size=1440 all=22763 active=1338 piece=bs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=154 size=1460 all=22849 active=1424 piece=▁wrap\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=152 size=1480 all=22986 active=1561 piece=method\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=150 size=1500 all=23065 active=1640 piece=▁second\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=150 min_freq=79\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=148 size=1520 all=23144 active=1233 piece=first\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=146 size=1540 all=23221 active=1310 piece=▁nonce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=143 size=1560 all=23309 active=1398 piece=mbda\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=141 size=1580 all=23383 active=1472 piece=▁ref\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=138 size=1600 all=23496 active=1585 piece=▁act\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=138 min_freq=75\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=1620 all=23561 active=1238 piece=TRAN\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=134 size=1640 all=23636 active=1313 piece=▁point\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=1660 all=23750 active=1427 piece=lean\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=1680 all=23853 active=1530 piece=angle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=129 size=1700 all=23923 active=1600 piece=regist\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=129 min_freq=71\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=127 size=1720 all=23958 active=1225 piece=▁grid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=1740 all=23987 active=1254 piece=ubt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=1760 all=24109 active=1376 piece=private\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121 size=1780 all=24197 active=1464 piece=▁you\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=1800 all=24250 active=1517 piece=▁timestamp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=119 min_freq=66\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=1820 all=24331 active=1293 piece=▁order\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117 size=1840 all=24364 active=1326 piece=▁created\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=1860 all=24440 active=1402 piece=40\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114 size=1880 all=24516 active=1478 piece=▁assertIs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=1900 all=24606 active=1568 piece=inate\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=112 min_freq=63\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=111 size=1920 all=24678 active=1299 piece=ordinate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=1940 all=24753 active=1374 piece=('\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=1960 all=24852 active=1473 piece=teraction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=1980 all=24962 active=1583 piece=tz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105 size=2000 all=25053 active=1674 piece=▁25\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=105 min_freq=59\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=2020 all=25142 active=1334 piece=▁patch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=2040 all=25206 active=1398 piece=center\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=101 size=2060 all=25281 active=1473 piece=▁HTTPBadRequest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=2080 all=25383 active=1575 piece=parameters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=2100 all=25464 active=1656 piece=settings\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=55\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=2120 all=25516 active=1326 piece=▁cpplint\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=2140 all=25578 active=1388 piece=▁www\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=2160 all=25634 active=1444 piece=RI\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=2180 all=25672 active=1482 piece=arDown\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=2200 all=25720 active=1530 piece=▁now\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=91 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=2220 all=25812 active=1378 piece=wra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=2240 all=25904 active=1470 piece=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=2260 all=26000 active=1566 piece=▁perform\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=2280 all=26047 active=1613 piece=▁called\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=2300 all=26134 active=1700 piece=existing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=87 min_freq=50\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=2320 all=26156 active=1329 piece=rtype\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=2340 all=26220 active=1393 piece=▁Union\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=2360 all=26251 active=1424 piece=▁sig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=2380 all=26287 active=1460 piece=CH\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=2400 all=26372 active=1545 piece=▁additional\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=83 min_freq=48\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=2420 all=26418 active=1365 piece=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=2440 all=26492 active=1439 piece=subject\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=2460 all=26561 active=1508 piece=pheri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=2480 all=26609 active=1556 piece=lops\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=2500 all=26658 active=1605 piece=▁dir\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=78 min_freq=45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=2520 all=26687 active=1360 piece=▁findPathwaysBy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=2540 all=26739 active=1412 piece=3_\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=2560 all=26819 active=1492 piece=▁rect\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=2580 all=26866 active=1539 piece=Plus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=2600 all=26891 active=1564 piece=HugeLines\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=75 min_freq=43\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=2620 all=26952 active=1406 piece=▁txt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=2640 all=26977 active=1431 piece=terminable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=2660 all=27060 active=1514 piece=▁head\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=2680 all=27084 active=1538 piece=flow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=2700 all=27132 active=1586 piece=validation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=72 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=2720 all=27183 active=1408 piece=▁Create\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=2740 all=27229 active=1454 piece=etadata\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=2760 all=27306 active=1531 piece=▁acc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2780 all=27357 active=1582 piece=CRE\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=2800 all=27439 active=1664 piece=▁reason\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=68 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=2820 all=27544 active=1476 piece=lative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=2840 all=27613 active=1545 piece=alog\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=2860 all=27618 active=1550 piece=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=2880 all=27762 active=1694 piece=▁weeks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=2900 all=27819 active=1751 piece=▁WWW\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=2920 all=27850 active=1422 piece=▁branch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=2940 all=27904 active=1476 piece=▁cre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2960 all=27939 active=1511 piece=parm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=2980 all=27957 active=1529 piece=▁energ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=3000 all=28013 active=1585 piece=▁hour\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=61 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=3020 all=28016 active=1403 piece=▁definition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=3040 all=28135 active=1522 piece=▁cut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=3060 all=28153 active=1540 piece=▁countPixels\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=3080 all=28225 active=1612 piece=Before\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=3100 all=28233 active=1620 piece=.9\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=3120 all=28328 active=1484 piece=asite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=3140 all=28344 active=1500 piece=address\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=3160 all=28413 active=1569 piece=lipse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=3180 all=28427 active=1583 piece=enrollment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=3200 all=28480 active=1636 piece=Logger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=56 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=3220 all=28484 active=1424 piece=▁preprocess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=3240 all=28599 active=1539 piece=glob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=3260 all=28628 active=1568 piece=▁callable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3280 all=28657 active=1597 piece=itize\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=3300 all=28661 active=1601 piece=▁attribute\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=54 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3320 all=28729 active=1502 piece=moid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=3340 all=28771 active=1544 piece=▁ChaCha\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3360 all=28814 active=1587 piece=dia\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=3380 all=28869 active=1642 piece=vious\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3400 all=28909 active=1682 piece=rev\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3420 all=28960 active=1492 piece=solve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=3440 all=28968 active=1500 piece=▁unpack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3460 all=29032 active=1564 piece=olute\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=3480 all=29051 active=1583 piece=▁getPathwaysBy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3500 all=29101 active=1633 piece=▁geo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=49 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=3520 all=29124 active=1476 piece=▁Distribution\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3540 all=29201 active=1553 piece=▁Per\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=3560 all=29214 active=1566 piece=webservice\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3580 all=29296 active=1648 piece=bout\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3600 all=29322 active=1674 piece=ational\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=3620 all=29332 active=1468 piece=▁representing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3640 all=29411 active=1547 piece=▁man\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=3660 all=29422 active=1558 piece=scriptor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3680 all=29513 active=1649 piece=sim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=3700 all=29551 active=1687 piece=expired\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3720 all=29549 active=1476 piece=VP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3740 all=29614 active=1541 piece=▁PIL\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=3760 all=29638 active=1565 piece=▁storage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3780 all=29734 active=1661 piece=lfor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3800 all=29789 active=1716 piece=ported\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=3820 all=29793 active=1490 piece=orientation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3840 all=29872 active=1569 piece=spec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=3860 all=29899 active=1596 piece=▁failed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3880 all=29964 active=1661 piece=gr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3900 all=30005 active=1702 piece=▁want\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=3920 all=30006 active=1502 piece=Metadata\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3940 all=30074 active=1570 piece=non\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3960 all=30125 active=1621 piece=▁Mock\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=3980 all=30140 active=1636 piece=▁expired\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=4000 all=30168 active=1664 piece=Port\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=4020 all=30214 active=1545 piece=counts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=4040 all=30221 active=1552 piece=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=4060 all=30312 active=1643 piece=▁ter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=4080 all=30325 active=1656 piece=▁times\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=4100 all=30321 active=1652 piece=▁stoptime\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=4120 all=30368 active=1564 piece=alt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=4140 all=30416 active=1612 piece=▁mak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=4160 all=30450 active=1646 piece=dataset\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4180 all=30451 active=1647 piece=1:\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4200 all=30536 active=1732 piece=▁Ch\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4220 all=30565 active=1552 piece=▁tsn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4240 all=30579 active=1566 piece=missing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=4260 all=30569 active=1556 piece=▁ensemble\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4280 all=30642 active=1629 piece=New\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4300 all=30693 active=1680 piece=plic\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4320 all=30713 active=1550 piece=others\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4340 all=30714 active=1551 piece=pubtator\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=4360 all=30701 active=1538 piece=▁specification\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4380 all=30752 active=1589 piece=opts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4400 all=30777 active=1614 piece=comple\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4420 all=30777 active=1535 piece=▁tmpdir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=4440 all=30767 active=1525 piece=updateCache\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4460 all=30872 active=1630 piece=OKEN\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4480 all=30891 active=1649 piece=slash\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=4500 all=30905 active=1663 piece=▁runner\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=33 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4520 all=30902 active=1543 piece=/#\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4540 all=30950 active=1591 piece=Sep\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4560 all=30994 active=1635 piece=eded\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4580 all=31012 active=1653 piece=▁chun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4600 all=31020 active=1661 piece=Segment\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=4620 all=31030 active=1558 piece=▁alphabet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4640 all=31051 active=1579 piece=Sup\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4660 all=31092 active=1620 piece=▁inp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4680 all=31106 active=1634 piece=clusion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=4700 all=31109 active=1637 piece=▁species\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=31 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4720 all=31145 active=1592 piece=Dec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4740 all=31187 active=1634 piece=Save\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4760 all=31214 active=1661 piece=ident\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4780 all=31235 active=1682 piece=▁Affin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4800 all=31228 active=1675 piece=▁Address\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=4820 all=31228 active=1561 piece=blacklisted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4840 all=31294 active=1627 piece=UTM\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4860 all=31343 active=1676 piece=roid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4880 all=31364 active=1697 piece=▁your\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4900 all=31369 active=1702 piece=▁future\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=29 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=4920 all=31356 active=1556 piece=▁measurement\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4940 all=31433 active=1633 piece=▁IO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4960 all=31463 active=1663 piece=▁sci\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=4980 all=31478 active=1678 piece=bounds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=5000 all=31487 active=1687 piece=Convert\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=5020 all=31482 active=1570 piece=▁through\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=5040 all=31483 active=1571 piece=▁serialized\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5060 all=31513 active=1601 piece=NC\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5080 all=31540 active=1628 piece=delt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5100 all=31572 active=1660 piece=▁YAML\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5120 all=31587 active=1594 piece=▁curve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5140 all=31597 active=1604 piece=▁offset\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5160 all=31591 active=1598 piece=▁notebook\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=5180 all=31574 active=1581 piece=▁LimitsBuilder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5200 all=31629 active=1636 piece=ikk\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5220 all=31673 active=1620 piece=bian\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5240 all=31710 active=1657 piece=ently\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5260 all=31739 active=1686 piece=tected\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5280 all=31738 active=1685 piece=Registry\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=5300 all=31731 active=1678 piece=recurrents\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5320 all=31797 active=1653 piece=Pod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5340 all=31838 active=1694 piece=▁0.7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5360 all=31870 active=1726 piece=▁MAXD\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5380 all=31868 active=1724 piece=profile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=5400 all=31863 active=1719 piece=mplemented\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=25 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5420 all=31911 active=1638 piece=sa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5440 all=31942 active=1669 piece=▁nk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5460 all=31958 active=1685 piece=▁VNC\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5480 all=31963 active=1690 piece=slots\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5500 all=31980 active=1707 piece=▁Input\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5520 all=31981 active=1600 piece=manager\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5540 all=31989 active=1608 piece=▁conveni\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5560 all=31975 active=1594 piece=fahrenheit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=5580 all=31963 active=1582 piece=▁pixCountMax\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5600 all=32023 active=1642 piece=ARN\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5620 all=32075 active=1651 piece=▁bw\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5640 all=32093 active=1669 piece=▁uid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5660 all=32104 active=1680 piece=ARNING\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5680 all=32101 active=1677 piece=▁adjust\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5700 all=32094 active=1670 piece=▁compile\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=5720 all=32085 active=1596 piece=▁supported\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5740 all=32142 active=1653 piece=FO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5760 all=32205 active=1716 piece=dix\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5780 all=32240 active=1751 piece=▁128\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5800 all=32253 active=1764 piece=▁boto\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5820 all=32252 active=1611 piece=tested\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5840 all=32253 active=1612 piece=Ancestor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=5860 all=32247 active=1606 piece=▁TinyFatTable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5880 all=32325 active=1684 piece=01_\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5900 all=32349 active=1708 piece=13.4\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5920 all=32358 active=1623 piece=▁Mut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5940 all=32381 active=1646 piece=▁bins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5960 all=32383 active=1648 piece=▁pmids\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=5980 all=32379 active=1644 piece=umulated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=6000 all=32365 active=1630 piece=▁platform\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6020 all=32375 active=1629 piece=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6040 all=32443 active=1697 piece=clo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6060 all=32486 active=1740 piece=ighb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6080 all=32499 active=1753 piece=▁pal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6100 all=32517 active=1771 piece=plores\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6120 all=32517 active=1624 piece=formats\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6140 all=32510 active=1617 piece=pression\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6160 all=32510 active=1617 piece=▁northing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=6180 all=32493 active=1600 piece=▁TextSegment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6200 all=32517 active=1624 piece='),\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6220 all=32553 active=1661 piece=▁AB\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6240 all=32571 active=1679 piece=▁All\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6260 all=32574 active=1682 piece=cally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6280 all=32588 active=1696 piece=anging\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6300 all=32605 active=1713 piece=imation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6320 all=32597 active=1620 piece=▁changes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6340 all=32583 active=1606 piece=▁ValueType\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=6360 all=32567 active=1590 piece=mplementedError\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6380 all=32645 active=1668 piece=ENS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6400 all=32680 active=1703 piece=OrEx\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6420 all=32692 active=1644 piece=tter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6440 all=32708 active=1660 piece=elest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6460 all=32714 active=1666 piece=▁sure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6480 all=32726 active=1678 piece=▁taken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6500 all=32719 active=1671 piece=▁domain\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6520 all=32714 active=1630 piece=▁GetUInt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6540 all=32698 active=1614 piece=structure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6560 all=32695 active=1611 piece=▁WebClient\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=6580 all=32680 active=1596 piece=▁internally\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6600 all=32720 active=1636 piece=LIP\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6620 all=32747 active=1660 piece=ved\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6640 all=32763 active=1676 piece=ietf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6660 all=32784 active=1697 piece=▁ear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=6680 all=32798 active=1711 piece=tplus\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: bpe_model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: bpe_model.vocab\n"
     ]
    }
   ],
   "source": [
    "run_spm = input(\"Train new tokenizer (needed if no .model file in project root)? (y/n): \").lower() == \"y\"\n",
    "tokenizer = Tokenizer(TOKENIZER_PREFIX)\n",
    "print('expected V size: ', VOCAB_SIZE)\n",
    "if run_spm:\n",
    "    tokenizer.train(vocab_size=VOCAB_SIZE, jsonl_file=TRAIN_FILE, sample_limit=10000)\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "tokenizer.load()\n",
    "\n",
    "# Sanity Check:\n",
    "ids = tokenizer.encode(\"def my_func(lalala: str) -> List[int]:\\n    print(\\\"foo bar\\\")\\n    return [3, 1, 4, 1, 5, 9]\")\n",
    "code = tokenizer.decode(ids)\n",
    "print(code)\n",
    "\n",
    "print(\"piece size: \", tokenizer.get_piece_size(), \" and vocab size: \", tokenizer.sp.vocab_size())\n",
    "\n",
    "for i in range(10):\n",
    "    print(tokenizer.sp.IdToPiece(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer ED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T15:47:42.959924Z",
     "start_time": "2025-05-02T15:44:01.391717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v size:  7017\n",
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:   0%|          | 0/9 [03:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m train_new_model = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWould you like to train a new model? (y/n, where n is loading old weights): \u001b[39m\u001b[33m\"\u001b[39m).lower() == \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_new_model:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading old weights...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, device, tokenizer, model_type)\u001b[39m\n\u001b[32m     79\u001b[39m dec_pad_mask = (dec_input_ids == PAD_TOKEN_ID)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Getting the probability distributions for the prompts...\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_pad_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03mFor understanding this dimension change, understand that the logits are of\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03mdimension (B,S,V) (see forward() function of base model for explanantion) and the targets are of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03mThe .view() function allows us to do this my making the last dimension of each tensor account for each entry.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m loss = criterion(logits.view(-\u001b[32m1\u001b[39m, vocab_size), target_ids.view(-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/LSU/Foundational-Models/FinalProject/PythonTestAI/ModifiedProj2/FinalProjModels.py:54\u001b[39m, in \u001b[36mTransformerEDLanguageModel.forward\u001b[39m\u001b[34m(self, enc_input_ids, dec_input_ids, src_padding_mask, tgt_padding_mask)\u001b[39m\n\u001b[32m     51\u001b[39m tgt_seq_len = dec_input_ids.size(\u001b[32m1\u001b[39m)\n\u001b[32m     52\u001b[39m tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device=enc_input_ids.device)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_padding_mask\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.fc(out)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/transformer.py:272\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m src.size(-\u001b[32m1\u001b[39m) != \u001b[38;5;28mself\u001b[39m.d_model \u001b[38;5;129;01mor\u001b[39;00m tgt.size(-\u001b[32m1\u001b[39m) != \u001b[38;5;28mself\u001b[39m.d_model:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    269\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m memory = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m output = \u001b[38;5;28mself\u001b[39m.decoder(\n\u001b[32m    279\u001b[39m     tgt,\n\u001b[32m    280\u001b[39m     memory,\n\u001b[32m   (...)\u001b[39m\u001b[32m    286\u001b[39m     memory_is_causal=memory_is_causal,\n\u001b[32m    287\u001b[39m )\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/transformer.py:511\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    508\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    519\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/transformer.py:904\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    900\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    902\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    903\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m     )\n\u001b[32m    906\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/transformer.py:918\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    912\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    913\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    916\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    917\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/modules/activation.py:1368\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1342\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1343\u001b[39m         query,\n\u001b[32m   1344\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1365\u001b[39m         is_causal=is_causal,\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/berend-grandt-csc-4700-ghawaly-project-2/lib/python3.13/site-packages/torch/nn/functional.py:6278\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6275\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6276\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6278\u001b[39m attn_output = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m   6280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6281\u001b[39m attn_output = (\n\u001b[32m   6282\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6283\u001b[39m )\n\u001b[32m   6285\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from FinalProjModels import TransformerEDLanguageModel\n",
    "\n",
    "transformer_model = TransformerEDLanguageModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    enc_num_layers=NUM_LAYERS,\n",
    "    dec_num_layers=NUM_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_token_id=PAD_TOKEN_ID,\n",
    "    seq_len=MAX_TRAIN_SEQ_LEN,\n",
    "    name=\"Transformer Encoder-Decoder\"\n",
    ").to(device)\n",
    "\n",
    "train_new_model = input(\"Would you like to train a new model? (y/n, where n is loading old weights): \").lower() == \"y\"\n",
    "if train_new_model:\n",
    "    train_model(transformer_model, device, tokenizer, transformer_model.name)\n",
    "else:\n",
    "    print(\"Loading old weights...\")\n",
    "    transformer_model.load_state_dict(torch.load(MODEL_WEIGHTS_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Transformer Encoder-Decoder (type q to quit): \n"
     ]
    }
   ],
   "source": [
    "prompt_model(transformer_model, tokenizer, transformer_model.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
